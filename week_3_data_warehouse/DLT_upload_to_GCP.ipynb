{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd5621f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m userdata\n\u001b[32m      4\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mDESTINATION__CREDENTIALS\u001b[39m\u001b[33m\"\u001b[39m] = userdata.get(\u001b[33m\"\u001b[39m\u001b[33mGCP_CREDENTIALS\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mBUCKET_URL\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mgs://your_bucket_url\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "os.environ[\"DESTINATION__CREDENTIALS\"] = userdata.get(\"GCP_CREDENTIALS\")\n",
    "os.environ[\"BUCKET_URL\"] = \"gs://your_bucket_url\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b989fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install for production\n",
    "%%capture\n",
    "!pip install dlt[bigquery, gs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240106c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install for testing\n",
    "%%capture\n",
    "!pip install dlt[duckdb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c8f115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlt\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dlt.destinations import filesystem\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3398924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dlt source to download and process Parquet files as resources\n",
    "@dlt.source(name=\"rides\")\n",
    "def download_parquet():\n",
    "    prefix = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata\"\n",
    "    for month in range(1, 7):\n",
    "        file_name = f\"yellow_tripdata_2024-0{month}.parquet\"\n",
    "        url = f\"{prefix}_2024-0{month}.parquet\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        df = pd.read_parquet(BytesIO(response.content))\n",
    "\n",
    "        # Return the dataframe as a dlt resource for ingestion\n",
    "        yield dlt.resource(df, name=file_name)\n",
    "\n",
    "\n",
    "# Initialize the pipeline\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"rides_pipeline\",\n",
    "    destination=filesystem(layout=\"{schema_name}/{table_name}.{ext}\"),\n",
    "    dataset_name=\"rides_dataset\",\n",
    ")\n",
    "\n",
    "# Run the pipeline to load Parquet data into DuckDB\n",
    "load_info = pipeline.run(download_parquet(), loader_file_format=\"parquet\")\n",
    "\n",
    "# Print the results\n",
    "print(load_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2233a5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dlt resource to download and process Parquet files as single table\n",
    "@dlt.resource(name=\"rides\", write_disposition=\"replace\")\n",
    "def download_parquet():\n",
    "    prefix = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata'\n",
    "\n",
    "    for month in range(1, 7):\n",
    "        url = f\"{prefix}_2024-0{month}.parquet\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        df = pd.read_parquet(BytesIO(response.content))\n",
    "\n",
    "        yield df\n",
    "\n",
    "\n",
    "# Initialize the pipeline\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"rides_pipeline\",\n",
    "    destination=\"duckdb\",  # Use DuckDB for testing\n",
    "    # destination=\"bigquery\",  # Use BigQuery for production\n",
    "    dataset_name=\"rides_dataset\",\n",
    ")\n",
    "\n",
    "# Run the pipeline to load Parquet data into DuckDB\n",
    "info = pipeline.run(download_parquet)\n",
    "\n",
    "# Print the results\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6796992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "conn = duckdb.connect(f\"{pipeline.pipeline_name}.duckdb\")\n",
    "\n",
    "# Set search path to the dataset\n",
    "conn.sql(f\"SET search_path = '{pipeline.dataset_name}'\")\n",
    "\n",
    "# Describe the dataset to see loaded tables\n",
    "res = conn.sql(\"DESCRIBE\").df()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4587ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide a resource name to query a table of that name\n",
    "with pipeline.sql_client() as client:\n",
    "    with client.execute_query(f\"SELECT count(1) FROM rides\") as cursor:\n",
    "        data = cursor.df()\n",
    "print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
